{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The Sprint 8 Supervised Learning Project involves analyzing bank customers data to determine if a customer is going to leave the bank or not.  The bank figured it was cheaper to try and keep existing customers than go out and get new ones.  We are attempting to predict whether a customer is going to leave the bank soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#To begin I will import the modules and check the data for missing information, outliers or invalid info.  From there I will begin using different models to try and create a good F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n",
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "data_nan = pd.isna(data)\n",
    "print(data_nan.sum())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Since there is a large amount of NaN values in the tenure column I am going to change the NaN values to the mean of the column instead of deleting them to help with the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['Tenure'].fillna(data['Tenure'].mean(), inplace=True)\n",
    "data_nan = pd.isna(data)\n",
    "print(data_nan.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Starting out I am importing all the possible python packages we will be needing to use to study the dataset along with importing the data from the csv into a dataframe.  Next I will breaking the data into the target and features dataframes to seperate them for a target dataset.  Then from there breaking them down further to get the training, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Exited']\n",
    "features = data.drop(['Exited', 'Surname', 'CustomerId'], axis=1)\n",
    "categorical_features = [\"Geography\", \"Gender\"]\n",
    "categorical_features = [col for col in categorical_features if col in features.columns]\n",
    "numerical_features = [col for col in features.columns if col not in categorical_features]\n",
    "features = pd.get_dummies(features, drop_first=True)\n",
    "\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features)], remainder='passthrough'  # Scale numerical features  \n",
    ")\n",
    "\n",
    "features_train = preprocessor.fit_transform(features_train)\n",
    "features_valid = preprocessor.transform(features_valid)\n",
    "features_test = preprocessor.transform(features_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Now I am going to begin testing different models on the data to see which ones have the best scores.  I will be starting out with the Decision Tree Classifier model and I will have hyperparameters on it to see which depth and min samples give me the best F1 and AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Classifier Hyperparameters: {'max_depth': 6, 'min_samples_split': 5}\n",
      "Best Decision Tree Classifier F1 Score: 0.5696969696969697\n",
      "Decision Tree Classifier AUC ROC Score: 0.685660752847525\n"
     ]
    }
   ],
   "source": [
    "max_depth_values_dtc = [3, 6, 10, None] \n",
    "min_samples_split_values_dtc = [2, 3, 4, 5]\n",
    "best_score_dtc = 0\n",
    "best_params_dtc = {}\n",
    "\n",
    "for max_depth in max_depth_values_dtc:\n",
    "    for min_samples_split in min_samples_split_values_dtc:\n",
    "        model_dtc = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=12345)\n",
    "        model_dtc.fit(features_train, target_train)\n",
    "        predicted_valid_dtc = model_dtc.predict(features_valid)\n",
    "        f1_dtc = f1_score(target_valid, predicted_valid_dtc)\n",
    "        auc_roc_dtc = roc_auc_score(target_valid, predicted_valid_dtc)\n",
    "        if f1_dtc > best_score_dtc:\n",
    "            best_score_dtc = f1_dtc\n",
    "            best_params_dtc = {\"max_depth\": max_depth, \"min_samples_split\": min_samples_split}\n",
    "\n",
    "print(\"Best Decision Tree Classifier Hyperparameters:\", best_params_dtc)\n",
    "print(\"Best Decision Tree Classifier F1 Score:\", best_score_dtc)\n",
    "print(\"Decision Tree Classifier AUC ROC Score:\", auc_roc_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#From my findings the decision tree classifier model did not achieve of the F1 score requirement of 0.57.  We tuned hyperparameters and it still did not score high enough.  We are going to try different models and oversampling/undersampling to improve the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression F1 Score: 0.3350253807106599\n",
      "Logistic Regression AUC ROC Score: 0.5950329363231087\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_lr.fit(features_train, target_train)\n",
    "predicted_valid_lr = model_lr.predict(features_valid)\n",
    "f1_lr = f1_score(target_valid, predicted_valid_lr)\n",
    "auc_roc_lr = roc_auc_score(target_valid, predicted_valid_lr)\n",
    "\n",
    "print(\"Best Logistic Regression F1 Score:\", f1_lr)\n",
    "print(\"Logistic Regression AUC ROC Score:\", auc_roc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Because we have extreme class imbalance the model is predicting an extremely low F1 score of 0.34 because there are far more 0s in the data than 1s for the 'Exited' variable.   To adjust for the class imbalance and the poor model we are going to encode the categorical variables (Geography and Gender).  Then we will scale Credit Score, Age and Estimated Salary to normalize the continuous variables.  From there we will use oversampling to help balance the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#I deleted the second logistic regression model because it had the scaler and split the data again.  I just moved the scaler to the top before I split the data then reran the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classifier Hyperparameters: {'best_depth': 10, 'best_estimators': 13, 'best min samples split': 10}\n",
      "Best Random Forest Classifier F1 Score: 0.6116279069767442\n",
      "Random Forest Classifier AUC ROC Score: 0.8448272733321637\n"
     ]
    }
   ],
   "source": [
    "best_est = 0\n",
    "best_depth = 0\n",
    "min_samples_split_values = [4, 6, 8, 10]\n",
    "min_samples_leaf_values = [1, 2, 4]\n",
    "best_score_rfc = 0\n",
    "best_params_rfc = {}\n",
    "\n",
    "\n",
    "for est in range(10, 20):  \n",
    "    for depth in range(10, 15, 20):\n",
    "            for min_samples_split in min_samples_split_values:\n",
    "                model_rfc = RandomForestClassifier(n_estimators=est, max_depth=depth, min_samples_split=min_samples_split, class_weight=\"balanced\", random_state=12345)  \n",
    "                model_rfc.fit(features_train, target_train)\n",
    "                predicted_valid_rfc = model_rfc.predict(features_valid)\n",
    "                f1_rfc = f1_score(target_valid, predicted_valid_rfc)\n",
    "                auc_roc_rfc = roc_auc_score(target_valid, model_rfc.predict_proba(features_valid)[:, 1])\n",
    "            \n",
    "                if f1_rfc > best_score_rfc:\n",
    "                    best_score_rfc = f1_rfc\n",
    "                    best_params_rfc = {\"best_depth\": depth, \"best_estimators\": est, \"best min samples split\": min_samples_split}\n",
    "\n",
    "print(\"Best Random Forest Classifier Hyperparameters:\", best_params_rfc) \n",
    "print(\"Best Random Forest Classifier F1 Score:\", best_score_rfc)\n",
    "print(\"Random Forest Classifier AUC ROC Score:\", auc_roc_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#After scaling the credit score, age and salary then changing categorical variables to numbers while also adding estimators, depth, min samples split and min samples leaf I got a F1 score of 0.61.  Adding the additional parameters helped and also provided me with an AUC ROC of 0.845."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: 0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n",
      "Class Percentages: 0    79.63\n",
      "1    20.37\n",
      "Name: Exited, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_counts = data['Exited'].value_counts()\n",
    "class_percentages = data['Exited'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Class Counts:\", class_counts)\n",
    "print(\"Class Percentages:\", class_percentages)\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=data['Exited'], palette=\"coolwarm\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution in Target Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Looking into the data we realize there is imbalance in our information.  We need to upsample the 1s (or the exited) variables to help get balance for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score after Upsampling: 0.34425176621708414\n",
      "         RowNumber  CreditScore          Age       Tenure      Balance  \\\n",
      "count  5879.000000  5879.000000  5879.000000  5879.000000  5879.000000   \n",
      "mean      0.014500    -0.002944    -0.013660    -0.008653     0.005299   \n",
      "std       0.995805     0.985473     0.982689     0.987913     1.001109   \n",
      "min      -1.722633    -3.140255    -1.986549    -1.829601    -1.233163   \n",
      "25%      -0.839357    -0.699824    -0.657902    -0.737618    -1.233163   \n",
      "50%       0.013436    -0.004041    -0.183385    -0.009629     0.327503   \n",
      "75%       0.869520     0.670972     0.386035     0.718360     0.825085   \n",
      "max       1.740845     2.052152     5.036300     1.810342     2.345224   \n",
      "\n",
      "       NumOfProducts    HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
      "count    5879.000000  5879.000000     5879.000000      5879.000000   \n",
      "mean       -0.021479    -0.003498       -0.040287         0.007581   \n",
      "std         1.001674     1.001676        1.001438         0.998760   \n",
      "min        -0.891560    -1.556504       -1.055187        -1.721610   \n",
      "25%        -0.891560    -1.556504       -1.055187        -0.847228   \n",
      "50%        -0.891560     0.642466        0.947699         0.012869   \n",
      "75%         0.830152     0.642466        0.947699         0.844150   \n",
      "max         4.273576     0.642466        0.947699         1.736483   \n",
      "\n",
      "       Geography_Germany  Geography_Spain  Gender_Male  \n",
      "count        5879.000000      5879.000000  5879.000000  \n",
      "mean            0.246470         0.252934     0.540398  \n",
      "std             0.430992         0.434731     0.498408  \n",
      "min             0.000000         0.000000     0.000000  \n",
      "25%             0.000000         0.000000     0.000000  \n",
      "50%             0.000000         0.000000     1.000000  \n",
      "75%             0.000000         1.000000     1.000000  \n",
      "max             1.000000         1.000000     1.000000  \n",
      "count    5879.000000\n",
      "mean        0.508250\n",
      "std         0.499974\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: Exited, dtype: float64\n",
      "      RowNumber  CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
      "1827  -0.636377    -0.471358  0.480939 -0.010470 -1.233163       0.830152   \n",
      "3756   0.675719     0.162116  0.386035 -1.465606  1.136149      -0.891560   \n",
      "4911  -1.535586     1.875610 -0.183385 -0.010470  1.201496       0.830152   \n",
      "388   -0.873649    -1.011368 -1.417129 -0.009629 -1.233163       0.830152   \n",
      "3374  -1.220724    -0.606361 -1.227322 -0.010470  0.941350       0.830152   \n",
      "4372  -1.385602     1.013670 -0.088482  0.718360  0.332628       0.830152   \n",
      "5866   0.812540    -1.852538 -0.183385 -0.009629  1.064045       0.830152   \n",
      "2619  -0.929417     0.058267  1.050359 -1.101612 -1.233163       0.830152   \n",
      "3928  -1.641925     1.190212 -1.796742 -0.737618  0.694171       0.830152   \n",
      "4298   1.491796     0.224424  0.575842  0.354365 -0.066038      -0.891560   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany  \\\n",
      "1827   0.642466        0.947699        -0.317927                0.0   \n",
      "3756  -1.556504       -1.055187         0.730564                0.0   \n",
      "4911   0.642466        0.947699         0.634439                0.0   \n",
      "388    0.642466       -1.055187        -1.246691                0.0   \n",
      "3374  -1.556504       -1.055187         0.549270                1.0   \n",
      "4372  -1.556504        0.947699         1.392210                0.0   \n",
      "5866   0.642466        0.947699         0.198411                1.0   \n",
      "2619   0.642466       -1.055187        -0.820221                0.0   \n",
      "3928  -1.556504        0.947699         0.877008                1.0   \n",
      "4298  -1.556504        0.947699         0.702196                0.0   \n",
      "\n",
      "      Geography_Spain  Gender_Male  \n",
      "1827              0.0          1.0  \n",
      "3756              1.0          1.0  \n",
      "4911              0.0          1.0  \n",
      "388               0.0          1.0  \n",
      "3374              0.0          0.0  \n",
      "4372              1.0          0.0  \n",
      "5866              0.0          0.0  \n",
      "2619              1.0          1.0  \n",
      "3928              0.0          1.0  \n",
      "4298              0.0          0.0  \n",
      "1827    1.0\n",
      "3756    0.0\n",
      "4911    1.0\n",
      "388     0.0\n",
      "3374    0.0\n",
      "4372    0.0\n",
      "5866    1.0\n",
      "2619    1.0\n",
      "3928    0.0\n",
      "4298    0.0\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features_train = pd.DataFrame(features_train, columns=features.columns)\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features = pd.DataFrame(features, columns=features.columns)\n",
    "    target = pd.Series(target, index=features.index) \n",
    "\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "\n",
    "model_upsample = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_upsample.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predicted_valid_upsample = model_upsample.predict(features_valid)\n",
    "\n",
    "f1_upsample = f1_score(target_valid, predicted_valid_upsample)\n",
    "\n",
    "print(\"F1 Score after Upsampling:\", f1_upsample)\n",
    "print(features_upsampled.describe())\n",
    "print(target_upsampled.describe())\n",
    "print(features_upsampled.head(10))\n",
    "print(target_upsampled.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#I upsampled the data and got an F1 that was even worse.  I believe this is because the logistic regression model does not do a good job of predicting with this data.  The F1 is no where near 0.59 and is at 0.34, very poor performance.  Next I am going to try to do the random forest classifier again but with updated hyperparamters, including additional ones along with upsampling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classifier Hyperparameters: {'best_depth': 10, 'best_estimators': 13, 'best min samples split': 10}\n",
      "Best Random Forest Classifier F1 Score: 0.2845927379784102\n",
      "Random Forest Classifier AUC ROC Score: 0.4809202209062479\n"
     ]
    }
   ],
   "source": [
    "best_est = 0\n",
    "best_depth = 0\n",
    "min_samples_split_values = [6, 8, 10]\n",
    "min_samples_leaf_values = [1, 2, 4]\n",
    "best_score_upsample = 0\n",
    "best_params_upsample = {}\n",
    "\n",
    "for est in range(10, 40, 10):  \n",
    "    for depth in range(10, 15):\n",
    "        for min_samples_leaf in min_samples_leaf_values:\n",
    "            for min_samples_split in min_samples_split_values:\n",
    "                model_upsample = RandomForestClassifier(n_estimators=est, max_depth=depth, min_samples_split=min_samples_split, random_state=12345)  \n",
    "                model_upsample.fit(features_upsampled, target_upsampled)\n",
    "                predicted_valid_upsample = model_upsample.predict(features_valid)\n",
    "                f1_upsample = f1_score(target_valid, predicted_valid_upsample)\n",
    "                auc_roc_upsample = roc_auc_score(target_valid, model_upsample.predict_proba(features_valid)[:, 1])\n",
    "            \n",
    "                if f1_upsample > best_score_upsample:\n",
    "                    best_score_upsample = f1_upsample\n",
    "                    best_params_upsample = {\"best_depth\": depth, \"best_estimators\": est, \"best min samples split\": min_samples_split, \"best min samples leaf\": min_samples_leaf}\n",
    "\n",
    "print(\"Best Random Forest Classifier Hyperparameters:\", best_params_rfc)\n",
    "print(\"Best Random Forest Classifier F1 Score:\", best_score_upsample)\n",
    "print(\"Random Forest Classifier AUC ROC Score:\", auc_roc_upsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#After upsampling the data and running the random forest classifier with the new data and the additional hyperparameters I still got a bad F1 score of 0.28.  How I dealt with class imbalances in the project was turning the categorical variables like geography and gender into numerical variables.  I also scaled the data for salary, age and balance as well.  I used an additional method of upsampling the data as well to make the data more balanced.  I used the 4 for repeat since according to the data above there were 8,000 zeros and 2,000 1s so I multiplied the 2,000 by 4 to get the numbers even.  Overall the model ended up getting an F1 score of 0.28 and an AUC ROC score of 0.48 which is a very poor performing mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classifier Hyperparameters: {'best_depth': 10, 'best_estimators': 13, 'best min samples split': 10}\n",
      "Best Random Forest Classifier F1 Score: 0.3352750809061488\n",
      "Random Forest Classifier AUC ROC Score: 0.5040058916397994\n"
     ]
    }
   ],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features = pd.DataFrame(features, columns=features.columns)\n",
    "    target = pd.Series(target, index=features.index) \n",
    "\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.25)\n",
    "\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "min_samples_split_values = [6, 8, 10]\n",
    "min_samples_leaf_values = [1, 2, 4]\n",
    "best_score_downsample = 0\n",
    "best_params_downsample = {}\n",
    "\n",
    "for est in range(10, 40, 10):  \n",
    "    for depth in range(10, 15):\n",
    "        for min_samples_leaf in min_samples_leaf_values:\n",
    "            for min_samples_split in min_samples_split_values:\n",
    "                model_downsample = RandomForestClassifier(n_estimators=est, max_depth=depth, min_samples_split=min_samples_split, random_state=12345)  \n",
    "                model_downsample.fit(features_downsampled, target_downsampled)\n",
    "                predicted_valid_downsample = model_downsample.predict(features_valid)\n",
    "                f1_downsample = f1_score(target_valid, predicted_valid_downsample)\n",
    "                auc_roc_downsample = roc_auc_score(target_valid, model_downsample.predict_proba(features_valid)[:, 1])\n",
    "            \n",
    "                if f1_downsample > best_score_downsample:\n",
    "                    best_score_downsample = f1_downsample\n",
    "                    best_params_downsample = {\"best_depth\": depth, \"best_estimators\": est, \"best min samples split\": min_samples_split, \"best min samples leaf\": min_samples_leaf}\n",
    "                                   \n",
    "print(\"Best Random Forest Classifier Hyperparameters:\", best_params_rfc)\n",
    "print(\"Best Random Forest Classifier F1 Score:\", best_score_downsample)\n",
    "print(\"Random Forest Classifier AUC ROC Score:\", auc_roc_downsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#I down sampled the data now to help with imbalance.  The downsampled got us a worse F1 and AUC ROC score, which makes sense because it is looking at less data so the model would be less accurate.  I used 0.25 for my fraction to get the 8,000 value to 2,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Now I am going to run my two best models on the testing data to see which one performs the best.  First I will run it on the original random forest model that did not have any down or upsampling and contained some hyperparameters.  In the original model run it had an F1 of 0.59 and an AUC ROC of 0.84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
      "0   0.867962    -0.886751 -0.373192  1.082354  1.232271      -0.891560   \n",
      "1  -0.541122     0.608663 -0.183385  1.082354  0.600563      -0.891560   \n",
      "2   0.365014     2.052152  0.480939 -0.737618  1.027098       0.830152   \n",
      "3  -1.290694    -1.457915 -1.417129  0.354365 -1.233163       0.830152   \n",
      "4  -0.435475     0.130961 -1.132419 -1.101612  1.140475      -0.891560   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany  \\\n",
      "0   0.642466       -1.055187        -0.187705                0.0   \n",
      "1  -1.556504       -1.055187        -0.333945                0.0   \n",
      "2  -1.556504        0.947699         1.503095                1.0   \n",
      "3   0.642466       -1.055187        -1.071061                0.0   \n",
      "4  -1.556504       -1.055187         1.524268                1.0   \n",
      "\n",
      "   Geography_Spain  Gender_Male  \n",
      "0              1.0          1.0  \n",
      "1              0.0          0.0  \n",
      "2              0.0          1.0  \n",
      "3              0.0          1.0  \n",
      "4              0.0          0.0  \n",
      "7479    0\n",
      "3411    0\n",
      "6027    0\n",
      "1247    0\n",
      "3716    0\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features_valid = pd.DataFrame(features_valid, columns=features.columns)\n",
    "print(features_train.head(5))\n",
    "print(target_train.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classifier Hyperparameters: {'best_depth': 14, 'best_estimators': 30, 'best min samples split': 10, 'best min samples leaf': 4}\n",
      "Best Random Forest Classifier F1 Score: 0.5591397849462365\n",
      "Random Forest Classifier AUC ROC Score: 0.839493645618471\n"
     ]
    }
   ],
   "source": [
    "best_est = 0\n",
    "best_depth = 0\n",
    "min_samples_split_values = [6, 8, 10]\n",
    "min_samples_leaf_values = [1, 2, 4]\n",
    "best_score_rfc_test = 0\n",
    "best_params_rfc_test = {}\n",
    "\n",
    "for est in range(10, 40, 10):  \n",
    "    for depth in range(10, 15):\n",
    "        for min_samples_leaf in min_samples_leaf_values:\n",
    "            for min_samples_split in min_samples_split_values:\n",
    "                model_rfc_test = RandomForestClassifier(n_estimators=est, max_depth=depth, min_samples_split=min_samples_split, random_state=12345)  \n",
    "                model_rfc_test.fit(features_train, target_train)\n",
    "                predicted_rfc_test = model_rfc_test.predict(features_valid)\n",
    "                f1_rfc_test = f1_score(target_valid, predicted_rfc_test)\n",
    "                auc_roc_rfc_test = roc_auc_score(target_valid, model_rfc_test.predict_proba(features_valid)[:, 1])\n",
    "            \n",
    "                if f1_rfc > best_score_rfc_test:\n",
    "                    best_score_rfc_test = f1_rfc_test\n",
    "                    best_params_rfc_test = {\"best_depth\": depth, \"best_estimators\": est, \"best min samples split\": min_samples_split, \"best min samples leaf\": min_samples_leaf}\n",
    "\n",
    "print(\"Best Random Forest Classifier Hyperparameters:\", best_params_rfc_test)\n",
    "print(\"Best Random Forest Classifier F1 Score:\", best_score_rfc_test)\n",
    "print(\"Random Forest Classifier AUC ROC Score:\", auc_roc_rfc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#On the test data set the F1 score fell slightly from 0.59 to 0.57, performing just slightly worse on the test data.  Next I am going to run the test set on the random forest classifier model with the upsampled data since that is the model that performed the best originally on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classifier Hyperparameters: {'best_depth': 14, 'best_estimators': 30, 'best min samples split': 10, 'best min samples leaf': 4}\n",
      "Best Random Forest Classifier F1 Score: 0.5925925925925927\n",
      "Random Forest Classifier AUC ROC Score: 0.839493645618471\n"
     ]
    }
   ],
   "source": [
    "best_est = 0\n",
    "best_depth = 0\n",
    "min_samples_split_values = [6, 8, 10]\n",
    "min_samples_leaf_values = [1, 2, 4]\n",
    "best_score_upsample_test = 0\n",
    "best_params_upsample_test = {}\n",
    "\n",
    "for est in range(10, 40, 10):  \n",
    "    for depth in range(10, 15):\n",
    "        for min_samples_leaf in min_samples_leaf_values:\n",
    "            for min_samples_split in min_samples_split_values:\n",
    "                model_upsample_test = RandomForestClassifier(n_estimators=est, max_depth=depth, min_samples_split=min_samples_split, random_state=12345)  \n",
    "                model_upsample_test.fit(features_train, target_train)\n",
    "                predicted_test_upsample = model_upsample_test.predict(features_valid)\n",
    "                f1_upsample_test = f1_score(target_valid, predicted_test_upsample)\n",
    "                auc_roc_upsample_test = roc_auc_score(target_valid, model_upsample_test.predict_proba(features_valid)[:, 1])\n",
    "            \n",
    "                if f1_upsample_test > best_score_upsample_test:\n",
    "                    best_score_upsample_test = f1_upsample_test\n",
    "                    best_params_upsample_test = {\"best_depth\": depth, \"best_estimators\": est, \"best min samples split\": min_samples_split, \"best min samples leaf\": min_samples_leaf}\n",
    "\n",
    "print(\"Best Random Forest Classifier Hyperparameters:\", best_params_rfc_test)\n",
    "print(\"Best Random Forest Classifier F1 Score:\", best_score_upsample_test)\n",
    "print(\"Random Forest Classifier AUC ROC Score:\", auc_roc_upsample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The upsampled model predicted better than the random forest classifier model that wasnt upsampled.  We got an F1score above 0.59 on the test data and 0.62 on the other data.  This model performed the best out of all of them so I would use this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classifier F1 Score: 0.6077981651376148\n",
      "Random Forest Classifier AUC ROC Score: 0.847438278683978\n"
     ]
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(n_estimators=13, max_depth=10, min_samples_split=10, class_weight=\"balanced\", random_state=12345)  \n",
    "model_rfc.fit(features_train, target_train)\n",
    "predicted_test_rfc = model_rfc.predict(features_test)\n",
    "f1_rfc_test = f1_score(target_test, predicted_test_rfc)\n",
    "auc_roc_rfc_test = roc_auc_score(target_test, model_rfc.predict_proba(features_test)[:, 1])\n",
    "                 \n",
    "print(\"Best Random Forest Classifier F1 Score:\", f1_rfc_test)\n",
    "print(\"Random Forest Classifier AUC ROC Score:\", auc_roc_rfc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Running the model on the test set gave us a worse F1 score and AUCROC score than before but it is still above the threshold of 0.59.  Adding class weight balanced to the parameters in the random forest classifier helped improve the model."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 157,
    "start_time": "2025-02-05T20:35:14.914Z"
   },
   {
    "duration": 840,
    "start_time": "2025-02-05T20:35:19.264Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-05T20:35:20.292Z"
   },
   {
    "duration": 92,
    "start_time": "2025-02-05T20:35:21.545Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-05T20:37:44.323Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-05T20:37:50.909Z"
   },
   {
    "duration": 172,
    "start_time": "2025-02-05T20:37:53.293Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-05T20:50:28.183Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-05T20:50:57.421Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-05T20:51:03.264Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-05T20:51:06.660Z"
   },
   {
    "duration": 119,
    "start_time": "2025-02-05T20:51:07.651Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-05T20:51:56.688Z"
   },
   {
    "duration": 72,
    "start_time": "2025-02-05T20:52:00.726Z"
   },
   {
    "duration": 74,
    "start_time": "2025-02-05T20:53:05.629Z"
   },
   {
    "duration": 73,
    "start_time": "2025-02-05T20:53:16.354Z"
   },
   {
    "duration": 787,
    "start_time": "2025-02-05T20:55:55.860Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-05T20:55:56.840Z"
   },
   {
    "duration": 382,
    "start_time": "2025-02-05T20:55:58.332Z"
   },
   {
    "duration": 117,
    "start_time": "2025-02-05T21:02:44.875Z"
   },
   {
    "duration": 49,
    "start_time": "2025-02-05T21:03:06.117Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-05T21:03:08.350Z"
   },
   {
    "duration": 841,
    "start_time": "2025-02-05T21:03:15.422Z"
   },
   {
    "duration": 311,
    "start_time": "2025-02-05T21:03:16.737Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-05T21:03:35.806Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-05T21:03:39.657Z"
   },
   {
    "duration": 30,
    "start_time": "2025-02-05T21:03:40.645Z"
   },
   {
    "duration": 180,
    "start_time": "2025-02-05T21:03:47.474Z"
   },
   {
    "duration": 798,
    "start_time": "2025-02-05T21:04:05.323Z"
   },
   {
    "duration": 169,
    "start_time": "2025-02-05T21:04:06.275Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-05T21:04:20.863Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-05T21:04:22.185Z"
   },
   {
    "duration": 68,
    "start_time": "2025-02-05T21:04:24.254Z"
   },
   {
    "duration": 68,
    "start_time": "2025-02-05T21:04:48.342Z"
   },
   {
    "duration": 59,
    "start_time": "2025-02-05T21:05:01.304Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-05T21:09:52.152Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-05T21:09:53.077Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-05T21:10:21.176Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-05T21:10:22.146Z"
   },
   {
    "duration": 30,
    "start_time": "2025-02-05T21:13:04.905Z"
   },
   {
    "duration": 26,
    "start_time": "2025-02-05T21:13:12.183Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-05T21:13:23.407Z"
   },
   {
    "duration": 31,
    "start_time": "2025-02-05T21:13:25.172Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-05T21:13:38.395Z"
   },
   {
    "duration": 195,
    "start_time": "2025-02-05T21:13:42.233Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-05T21:14:16.573Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-05T21:14:17.585Z"
   },
   {
    "duration": 60,
    "start_time": "2025-02-05T21:14:19.138Z"
   },
   {
    "duration": 105,
    "start_time": "2025-02-05T21:22:47.520Z"
   },
   {
    "duration": 833,
    "start_time": "2025-02-05T21:25:42.158Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-05T21:25:43.410Z"
   },
   {
    "duration": 314,
    "start_time": "2025-02-05T21:25:46.624Z"
   },
   {
    "duration": 82,
    "start_time": "2025-02-05T21:26:10.328Z"
   },
   {
    "duration": 762,
    "start_time": "2025-02-05T21:26:57.406Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-05T21:26:58.170Z"
   },
   {
    "duration": 314,
    "start_time": "2025-02-05T21:26:58.176Z"
   },
   {
    "duration": 450,
    "start_time": "2025-02-05T21:28:21.685Z"
   },
   {
    "duration": 508,
    "start_time": "2025-02-05T21:28:49.879Z"
   },
   {
    "duration": 557,
    "start_time": "2025-02-05T21:29:07.686Z"
   },
   {
    "duration": 710,
    "start_time": "2025-02-05T21:29:16.672Z"
   },
   {
    "duration": 582,
    "start_time": "2025-02-05T21:29:32.942Z"
   },
   {
    "duration": 584,
    "start_time": "2025-02-05T21:31:30.502Z"
   },
   {
    "duration": 539,
    "start_time": "2025-02-05T21:31:57.993Z"
   },
   {
    "duration": 779,
    "start_time": "2025-02-06T15:04:19.262Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-06T15:04:20.082Z"
   },
   {
    "duration": 536,
    "start_time": "2025-02-06T15:04:20.909Z"
   },
   {
    "duration": 533,
    "start_time": "2025-02-06T15:06:39.277Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-06T15:26:45.350Z"
   },
   {
    "duration": 540,
    "start_time": "2025-02-06T15:27:10.964Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-06T15:27:13.169Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-06T15:27:28.130Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-06T15:40:23.041Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-06T15:40:24.490Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-06T15:40:25.219Z"
   },
   {
    "duration": 144,
    "start_time": "2025-02-06T15:40:26.039Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-06T15:42:39.966Z"
   },
   {
    "duration": 29,
    "start_time": "2025-02-06T15:42:41.086Z"
   },
   {
    "duration": 23,
    "start_time": "2025-02-06T15:44:49.452Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-06T15:45:26.082Z"
   },
   {
    "duration": 518,
    "start_time": "2025-02-06T15:45:27.469Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-06T15:45:54.555Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-06T15:49:47.814Z"
   },
   {
    "duration": 546,
    "start_time": "2025-02-06T15:49:51.127Z"
   },
   {
    "duration": 29,
    "start_time": "2025-02-06T15:49:57.843Z"
   },
   {
    "duration": 408,
    "start_time": "2025-02-06T15:54:59.378Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-06T15:58:42.215Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-06T15:59:47.877Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-06T15:59:48.334Z"
   },
   {
    "duration": 545,
    "start_time": "2025-02-06T15:59:48.702Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-06T15:59:49.409Z"
   },
   {
    "duration": 147,
    "start_time": "2025-02-06T15:59:50.735Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-06T16:00:20.469Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-06T16:09:32.775Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-06T16:09:33.724Z"
   },
   {
    "duration": 550,
    "start_time": "2025-02-06T16:09:34.461Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-06T16:09:35.595Z"
   },
   {
    "duration": 32,
    "start_time": "2025-02-06T16:09:36.743Z"
   },
   {
    "duration": 52,
    "start_time": "2025-02-06T16:15:29.192Z"
   },
   {
    "duration": 189,
    "start_time": "2025-02-06T16:15:45.998Z"
   },
   {
    "duration": 96,
    "start_time": "2025-02-06T16:18:43.028Z"
   },
   {
    "duration": 21,
    "start_time": "2025-02-06T16:18:55.687Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-06T16:19:10.501Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-06T16:19:11.013Z"
   },
   {
    "duration": 554,
    "start_time": "2025-02-06T16:19:11.507Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-06T16:19:12.181Z"
   },
   {
    "duration": 21,
    "start_time": "2025-02-06T16:19:13.200Z"
   },
   {
    "duration": 7062,
    "start_time": "2025-02-06T16:19:15.730Z"
   },
   {
    "duration": 11937,
    "start_time": "2025-02-06T16:21:48.449Z"
   },
   {
    "duration": 18459,
    "start_time": "2025-02-06T16:22:10.856Z"
   },
   {
    "duration": 55358,
    "start_time": "2025-02-06T16:31:10.316Z"
   },
   {
    "duration": 68,
    "start_time": "2025-02-06T16:33:23.038Z"
   },
   {
    "duration": 67,
    "start_time": "2025-02-06T16:37:49.112Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-06T16:40:04.652Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-06T16:41:29.767Z"
   },
   {
    "duration": 447,
    "start_time": "2025-02-06T16:42:00.848Z"
   },
   {
    "duration": 155,
    "start_time": "2025-02-06T16:42:34.429Z"
   },
   {
    "duration": 43,
    "start_time": "2025-02-06T16:42:40.877Z"
   },
   {
    "duration": 57,
    "start_time": "2025-02-06T16:43:37.623Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-06T16:43:47.332Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-06T16:44:30.285Z"
   },
   {
    "duration": 46,
    "start_time": "2025-02-06T16:46:09.149Z"
   },
   {
    "duration": 47,
    "start_time": "2025-02-06T16:47:19.819Z"
   },
   {
    "duration": 35,
    "start_time": "2025-02-06T16:47:59.411Z"
   },
   {
    "duration": 61,
    "start_time": "2025-02-06T16:48:04.114Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-06T16:48:09.011Z"
   },
   {
    "duration": 35,
    "start_time": "2025-02-06T16:48:12.927Z"
   },
   {
    "duration": 35,
    "start_time": "2025-02-06T16:48:16.195Z"
   },
   {
    "duration": 50,
    "start_time": "2025-02-06T16:48:19.675Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-06T16:48:25.227Z"
   },
   {
    "duration": 36,
    "start_time": "2025-02-06T16:48:29.023Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-06T16:49:00.665Z"
   },
   {
    "duration": 36,
    "start_time": "2025-02-06T16:49:05.617Z"
   },
   {
    "duration": 1427,
    "start_time": "2025-02-06T19:49:52.610Z"
   },
   {
    "duration": 106,
    "start_time": "2025-02-06T19:50:12.740Z"
   },
   {
    "duration": 91,
    "start_time": "2025-02-06T19:50:53.226Z"
   },
   {
    "duration": 72,
    "start_time": "2025-02-06T19:50:58.651Z"
   },
   {
    "duration": 103,
    "start_time": "2025-02-06T19:51:03.157Z"
   },
   {
    "duration": 66,
    "start_time": "2025-02-06T19:51:07.905Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-06T19:54:04.805Z"
   },
   {
    "duration": 42,
    "start_time": "2025-02-06T19:54:19.751Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-06T19:54:20.421Z"
   },
   {
    "duration": 548,
    "start_time": "2025-02-06T19:54:21.242Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-06T19:54:25.196Z"
   },
   {
    "duration": 22,
    "start_time": "2025-02-06T19:54:28.174Z"
   },
   {
    "duration": 38012,
    "start_time": "2025-02-06T19:54:37.148Z"
   },
   {
    "duration": 124,
    "start_time": "2025-02-06T19:55:15.213Z"
   },
   {
    "duration": 193,
    "start_time": "2025-02-06T19:55:15.340Z"
   },
   {
    "duration": 65,
    "start_time": "2025-02-06T20:28:50.313Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-06T20:37:02.860Z"
   },
   {
    "duration": 153617,
    "start_time": "2025-02-06T20:37:47.883Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-06T20:41:44.549Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-06T20:41:53.101Z"
   },
   {
    "duration": 41151,
    "start_time": "2025-02-06T20:41:59.792Z"
   },
   {
    "duration": 41219,
    "start_time": "2025-02-06T20:43:08.627Z"
   },
   {
    "duration": 32668,
    "start_time": "2025-02-06T20:44:07.722Z"
   },
   {
    "duration": 24281,
    "start_time": "2025-02-06T20:45:00.583Z"
   },
   {
    "duration": 14807,
    "start_time": "2025-02-06T20:45:39.748Z"
   },
   {
    "duration": 24551,
    "start_time": "2025-02-06T20:46:05.427Z"
   },
   {
    "duration": 75790,
    "start_time": "2025-02-06T20:47:50.356Z"
   },
   {
    "duration": 74792,
    "start_time": "2025-02-06T20:50:05.967Z"
   },
   {
    "duration": 21430,
    "start_time": "2025-02-06T20:54:51.532Z"
   },
   {
    "duration": 36,
    "start_time": "2025-02-06T20:57:55.377Z"
   },
   {
    "duration": 37467,
    "start_time": "2025-02-06T20:57:58.643Z"
   },
   {
    "duration": 137,
    "start_time": "2025-02-06T21:15:49.793Z"
   },
   {
    "duration": 145,
    "start_time": "2025-02-06T21:16:25.951Z"
   },
   {
    "duration": 304,
    "start_time": "2025-02-06T21:16:50.351Z"
   },
   {
    "duration": 34817,
    "start_time": "2025-02-06T21:17:15.507Z"
   },
   {
    "duration": 34739,
    "start_time": "2025-02-06T21:23:07.955Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-07T09:05:54.747Z"
   },
   {
    "duration": 893,
    "start_time": "2025-02-07T09:11:29.499Z"
   },
   {
    "duration": 11,
    "start_time": "2025-02-07T09:11:30.394Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-07T09:18:19.788Z"
   },
   {
    "duration": 1096,
    "start_time": "2025-02-07T16:18:16.958Z"
   },
   {
    "duration": 39,
    "start_time": "2025-02-07T16:18:30.536Z"
   },
   {
    "duration": 42,
    "start_time": "2025-02-07T16:21:22.524Z"
   },
   {
    "duration": 38,
    "start_time": "2025-02-07T16:21:51.936Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-07T16:24:25.657Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-07T16:24:31.525Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-07T16:24:48.569Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-07T16:24:51.669Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-07T16:32:56.182Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-07T16:33:44.325Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-07T16:34:11.912Z"
   },
   {
    "duration": 396,
    "start_time": "2025-02-07T16:34:30.953Z"
   },
   {
    "duration": 398,
    "start_time": "2025-02-07T16:35:22.995Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-07T16:37:35.476Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-07T16:47:40.358Z"
   },
   {
    "duration": 22,
    "start_time": "2025-02-07T16:47:48.099Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-07T16:48:52.168Z"
   },
   {
    "duration": 394,
    "start_time": "2025-02-07T16:48:55.548Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-07T16:49:16.397Z"
   },
   {
    "duration": 18447,
    "start_time": "2025-02-07T16:49:43.028Z"
   },
   {
    "duration": 18561,
    "start_time": "2025-02-07T16:51:11.830Z"
   },
   {
    "duration": 415,
    "start_time": "2025-02-07T16:51:30.393Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-07T16:51:33.431Z"
   },
   {
    "duration": 815,
    "start_time": "2025-02-07T20:15:52.330Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-07T20:15:56.623Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-07T20:15:59.892Z"
   },
   {
    "duration": 392,
    "start_time": "2025-02-07T20:16:02.284Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-07T20:16:11.453Z"
   },
   {
    "duration": 18426,
    "start_time": "2025-02-07T20:16:19.255Z"
   },
   {
    "duration": 2013,
    "start_time": "2025-02-07T20:22:59.498Z"
   },
   {
    "duration": 297,
    "start_time": "2025-02-07T20:24:07.244Z"
   },
   {
    "duration": 21,
    "start_time": "2025-02-07T20:24:14.611Z"
   },
   {
    "duration": 103,
    "start_time": "2025-02-07T20:24:43.006Z"
   },
   {
    "duration": 104,
    "start_time": "2025-02-07T20:24:52.091Z"
   },
   {
    "duration": 162,
    "start_time": "2025-02-07T20:25:36.257Z"
   },
   {
    "duration": 58,
    "start_time": "2025-02-07T20:26:28.595Z"
   },
   {
    "duration": 55,
    "start_time": "2025-02-07T20:26:46.371Z"
   },
   {
    "duration": 54,
    "start_time": "2025-02-07T20:26:50.652Z"
   },
   {
    "duration": 33806,
    "start_time": "2025-02-07T20:27:58.292Z"
   },
   {
    "duration": 127,
    "start_time": "2025-02-07T20:30:09.988Z"
   },
   {
    "duration": 277,
    "start_time": "2025-02-07T20:30:17.479Z"
   },
   {
    "duration": 44,
    "start_time": "2025-02-07T20:30:36.952Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-07T20:30:37.887Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-07T20:30:39.155Z"
   },
   {
    "duration": 399,
    "start_time": "2025-02-07T20:30:41.162Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-07T20:30:43.436Z"
   },
   {
    "duration": 18485,
    "start_time": "2025-02-07T20:30:46.309Z"
   },
   {
    "duration": 101,
    "start_time": "2025-02-07T20:31:04.796Z"
   },
   {
    "duration": 47,
    "start_time": "2025-02-07T20:31:04.898Z"
   },
   {
    "duration": 230,
    "start_time": "2025-02-07T20:31:04.972Z"
   },
   {
    "duration": 808,
    "start_time": "2025-02-07T20:31:26.334Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-07T20:31:27.358Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-07T20:31:29.578Z"
   },
   {
    "duration": 395,
    "start_time": "2025-02-07T20:31:31.606Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-07T20:31:34.897Z"
   },
   {
    "duration": 18503,
    "start_time": "2025-02-07T20:31:39.282Z"
   },
   {
    "duration": 343,
    "start_time": "2025-02-07T20:31:57.787Z"
   },
   {
    "duration": 251,
    "start_time": "2025-02-07T20:31:58.132Z"
   },
   {
    "duration": 802,
    "start_time": "2025-02-07T20:33:14.945Z"
   },
   {
    "duration": 49,
    "start_time": "2025-02-07T20:34:36.022Z"
   },
   {
    "duration": 266,
    "start_time": "2025-02-07T20:34:50.659Z"
   },
   {
    "duration": 217,
    "start_time": "2025-02-07T20:36:32.937Z"
   },
   {
    "duration": 26408,
    "start_time": "2025-02-07T20:37:12.962Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-07T20:47:08.686Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-07T20:47:44.517Z"
   },
   {
    "duration": 34,
    "start_time": "2025-02-07T20:47:58.791Z"
   },
   {
    "duration": 34,
    "start_time": "2025-02-07T20:49:05.815Z"
   },
   {
    "duration": 9523,
    "start_time": "2025-02-07T20:49:26.806Z"
   },
   {
    "duration": 16228,
    "start_time": "2025-02-07T21:05:51.216Z"
   },
   {
    "duration": 16232,
    "start_time": "2025-02-07T21:07:50.047Z"
   },
   {
    "duration": 26424,
    "start_time": "2025-02-07T21:16:10.230Z"
   },
   {
    "duration": 17580,
    "start_time": "2025-02-07T21:18:39.860Z"
   },
   {
    "duration": 17516,
    "start_time": "2025-02-07T21:20:45.559Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-08T09:31:19.704Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-08T09:33:03.345Z"
   },
   {
    "duration": 817,
    "start_time": "2025-02-08T19:14:43.275Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-08T19:14:49.766Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-08T19:15:08.215Z"
   },
   {
    "duration": 146,
    "start_time": "2025-02-08T19:15:12.848Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-08T19:15:34.010Z"
   },
   {
    "duration": 30,
    "start_time": "2025-02-08T19:15:36.861Z"
   },
   {
    "duration": 843,
    "start_time": "2025-02-08T19:15:55.526Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-08T19:15:57.798Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-08T19:16:01.297Z"
   },
   {
    "duration": 145,
    "start_time": "2025-02-08T19:16:07.311Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-08T19:19:16.450Z"
   },
   {
    "duration": 385,
    "start_time": "2025-02-08T19:19:19.090Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-08T19:20:35.513Z"
   },
   {
    "duration": 16747,
    "start_time": "2025-02-08T19:20:55.394Z"
   },
   {
    "duration": 2043,
    "start_time": "2025-02-08T19:21:40.386Z"
   },
   {
    "duration": 46,
    "start_time": "2025-02-08T19:21:48.818Z"
   },
   {
    "duration": 400,
    "start_time": "2025-02-08T19:22:20.947Z"
   },
   {
    "duration": 100,
    "start_time": "2025-02-08T19:23:38.974Z"
   },
   {
    "duration": 25526,
    "start_time": "2025-02-08T19:23:43.296Z"
   },
   {
    "duration": 156,
    "start_time": "2025-02-08T19:24:45.069Z"
   },
   {
    "duration": 152,
    "start_time": "2025-02-08T19:25:57.970Z"
   },
   {
    "duration": 153,
    "start_time": "2025-02-08T19:26:11.529Z"
   },
   {
    "duration": 25509,
    "start_time": "2025-02-08T19:26:31.709Z"
   },
   {
    "duration": 99,
    "start_time": "2025-02-08T19:28:34.157Z"
   },
   {
    "duration": 23335,
    "start_time": "2025-02-08T19:28:40.724Z"
   },
   {
    "duration": 8723,
    "start_time": "2025-02-08T19:31:48.124Z"
   },
   {
    "duration": 8615,
    "start_time": "2025-02-08T19:32:09.100Z"
   },
   {
    "duration": 7546,
    "start_time": "2025-02-08T19:33:20.606Z"
   },
   {
    "duration": 16949,
    "start_time": "2025-02-08T19:36:05.476Z"
   },
   {
    "duration": 19055,
    "start_time": "2025-02-08T19:39:14.200Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-08T20:30:46.056Z"
   },
   {
    "duration": 158,
    "start_time": "2025-02-08T20:31:04.971Z"
   },
   {
    "duration": 794,
    "start_time": "2025-02-08T20:31:49.102Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-08T20:31:52.362Z"
   },
   {
    "duration": 154,
    "start_time": "2025-02-08T20:31:57.902Z"
   },
   {
    "duration": 48,
    "start_time": "2025-02-08T20:33:01.435Z"
   },
   {
    "duration": 22,
    "start_time": "2025-02-08T20:33:13.792Z"
   },
   {
    "duration": 354,
    "start_time": "2025-02-08T20:33:23.813Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-08T20:33:28.425Z"
   },
   {
    "duration": 16379,
    "start_time": "2025-02-08T20:33:59.939Z"
   },
   {
    "duration": 2103,
    "start_time": "2025-02-08T20:34:53.630Z"
   },
   {
    "duration": 32,
    "start_time": "2025-02-08T20:34:58.263Z"
   },
   {
    "duration": 26,
    "start_time": "2025-02-08T20:35:26.236Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-08T20:35:43.529Z"
   },
   {
    "duration": 32,
    "start_time": "2025-02-08T20:37:06.776Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-08T20:38:06.370Z"
   },
   {
    "duration": 16118,
    "start_time": "2025-02-08T20:38:23.789Z"
   },
   {
    "duration": 6621,
    "start_time": "2025-02-08T20:39:53.741Z"
   },
   {
    "duration": 170,
    "start_time": "2025-02-08T20:40:37.222Z"
   },
   {
    "duration": 69,
    "start_time": "2025-02-08T20:40:58.517Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-08T20:46:21.977Z"
   },
   {
    "duration": 58,
    "start_time": "2025-02-08T20:47:09.489Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-08T20:47:42.692Z"
   },
   {
    "duration": 51,
    "start_time": "2025-02-08T20:47:45.957Z"
   },
   {
    "duration": 53,
    "start_time": "2025-02-08T20:49:07.409Z"
   },
   {
    "duration": 58,
    "start_time": "2025-02-08T20:50:35.850Z"
   },
   {
    "duration": 842,
    "start_time": "2025-02-08T20:51:03.632Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-08T20:51:05.409Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-08T20:51:07.090Z"
   },
   {
    "duration": 353,
    "start_time": "2025-02-08T20:51:08.986Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-08T20:51:10.883Z"
   },
   {
    "duration": 16476,
    "start_time": "2025-02-08T20:51:13.101Z"
   },
   {
    "duration": 315,
    "start_time": "2025-02-08T20:51:36.641Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-08T20:51:40.172Z"
   },
   {
    "duration": 16129,
    "start_time": "2025-02-08T20:51:44.484Z"
   },
   {
    "duration": 6608,
    "start_time": "2025-02-08T20:52:00.616Z"
   },
   {
    "duration": 235,
    "start_time": "2025-02-08T20:52:24.464Z"
   },
   {
    "duration": 11,
    "start_time": "2025-02-08T20:52:31.986Z"
   },
   {
    "duration": 239,
    "start_time": "2025-02-08T20:52:33.486Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-08T20:53:07.869Z"
   },
   {
    "duration": 73,
    "start_time": "2025-02-08T20:53:11.314Z"
   },
   {
    "duration": 849,
    "start_time": "2025-02-08T20:53:37.779Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-08T20:53:38.630Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-08T20:53:39.007Z"
   },
   {
    "duration": 349,
    "start_time": "2025-02-08T20:53:39.905Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-08T20:53:40.436Z"
   },
   {
    "duration": 16433,
    "start_time": "2025-02-08T20:53:45.300Z"
   },
   {
    "duration": 320,
    "start_time": "2025-02-08T20:54:15.008Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-08T20:54:17.479Z"
   },
   {
    "duration": 16083,
    "start_time": "2025-02-08T20:54:19.794Z"
   },
   {
    "duration": 6714,
    "start_time": "2025-02-08T20:54:35.879Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-08T20:54:58.018Z"
   },
   {
    "duration": 446,
    "start_time": "2025-02-08T20:55:00.136Z"
   },
   {
    "duration": 156,
    "start_time": "2025-02-08T20:56:49.041Z"
   },
   {
    "duration": 833,
    "start_time": "2025-02-08T20:57:01.438Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-08T20:57:02.416Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-08T20:57:03.181Z"
   },
   {
    "duration": 349,
    "start_time": "2025-02-08T20:57:04.045Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-08T20:57:04.552Z"
   },
   {
    "duration": 16452,
    "start_time": "2025-02-08T20:57:05.700Z"
   },
   {
    "duration": 351,
    "start_time": "2025-02-08T20:57:22.155Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-08T20:57:22.508Z"
   },
   {
    "duration": 16215,
    "start_time": "2025-02-08T20:57:22.538Z"
   },
   {
    "duration": 6703,
    "start_time": "2025-02-08T20:57:46.685Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-08T20:57:53.390Z"
   },
   {
    "duration": 483,
    "start_time": "2025-02-08T20:57:53.395Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-08T20:58:28.583Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-08T20:59:04.782Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-08T21:14:40.941Z"
   },
   {
    "duration": 16380,
    "start_time": "2025-02-08T21:14:44.333Z"
   },
   {
    "duration": 6869,
    "start_time": "2025-02-08T21:15:00.715Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-08T21:15:07.595Z"
   },
   {
    "duration": 85,
    "start_time": "2025-02-08T21:15:07.604Z"
   },
   {
    "duration": 901,
    "start_time": "2025-02-08T21:21:43.344Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-08T21:21:44.315Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-08T21:21:45.195Z"
   },
   {
    "duration": 378,
    "start_time": "2025-02-08T21:21:47.959Z"
   },
   {
    "duration": 25,
    "start_time": "2025-02-08T21:21:51.079Z"
   },
   {
    "duration": 16313,
    "start_time": "2025-02-08T21:21:58.829Z"
   },
   {
    "duration": 342,
    "start_time": "2025-02-08T21:22:15.144Z"
   },
   {
    "duration": 35,
    "start_time": "2025-02-08T21:22:15.489Z"
   },
   {
    "duration": 16244,
    "start_time": "2025-02-08T21:22:15.527Z"
   },
   {
    "duration": 6610,
    "start_time": "2025-02-08T21:22:31.773Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-08T21:22:44.214Z"
   },
   {
    "duration": 16803,
    "start_time": "2025-02-08T21:22:45.910Z"
   },
   {
    "duration": 16811,
    "start_time": "2025-02-08T21:23:13.664Z"
   },
   {
    "duration": 16651,
    "start_time": "2025-02-08T21:25:35.941Z"
   },
   {
    "duration": 883,
    "start_time": "2025-02-10T20:05:07.643Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-10T20:05:08.607Z"
   },
   {
    "duration": 22,
    "start_time": "2025-02-10T20:05:09.734Z"
   },
   {
    "duration": 353,
    "start_time": "2025-02-10T20:05:10.942Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-10T20:05:11.496Z"
   },
   {
    "duration": 16509,
    "start_time": "2025-02-10T20:05:12.528Z"
   },
   {
    "duration": 2116,
    "start_time": "2025-02-10T20:05:29.039Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-10T20:05:31.156Z"
   },
   {
    "duration": 827,
    "start_time": "2025-02-10T20:32:36.278Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-10T20:32:37.107Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-10T20:32:37.116Z"
   },
   {
    "duration": 361,
    "start_time": "2025-02-10T20:32:37.141Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-10T20:32:37.513Z"
   },
   {
    "duration": 16577,
    "start_time": "2025-02-10T20:32:37.529Z"
   },
   {
    "duration": 2118,
    "start_time": "2025-02-10T20:32:54.114Z"
   },
   {
    "duration": 23,
    "start_time": "2025-02-10T20:32:56.235Z"
   },
   {
    "duration": 16353,
    "start_time": "2025-02-10T20:32:56.260Z"
   },
   {
    "duration": 6782,
    "start_time": "2025-02-10T20:33:12.615Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-10T20:33:19.399Z"
   },
   {
    "duration": 16933,
    "start_time": "2025-02-10T20:33:19.414Z"
   },
   {
    "duration": 16946,
    "start_time": "2025-02-10T20:33:36.348Z"
   },
   {
    "duration": 75,
    "start_time": "2025-02-10T20:33:53.296Z"
   },
   {
    "duration": 265,
    "start_time": "2025-02-10T20:34:35.429Z"
   },
   {
    "duration": 196,
    "start_time": "2025-02-10T20:34:55.239Z"
   },
   {
    "duration": 789,
    "start_time": "2025-02-10T20:35:13.797Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-10T20:35:14.589Z"
   },
   {
    "duration": 31,
    "start_time": "2025-02-10T20:35:14.597Z"
   },
   {
    "duration": 371,
    "start_time": "2025-02-10T20:35:14.630Z"
   },
   {
    "duration": 29,
    "start_time": "2025-02-10T20:35:15.003Z"
   },
   {
    "duration": 16747,
    "start_time": "2025-02-10T20:35:15.036Z"
   },
   {
    "duration": 380,
    "start_time": "2025-02-10T20:35:31.785Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-10T20:35:32.167Z"
   },
   {
    "duration": 848,
    "start_time": "2025-02-11T08:44:23.326Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-11T08:44:24.176Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-11T08:44:25.608Z"
   },
   {
    "duration": 354,
    "start_time": "2025-02-11T08:44:27.788Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-11T08:44:34.494Z"
   },
   {
    "duration": 2075,
    "start_time": "2025-02-11T08:44:41.648Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-11T08:44:46.281Z"
   },
   {
    "duration": 290,
    "start_time": "2025-02-11T08:44:57.897Z"
   },
   {
    "duration": 16635,
    "start_time": "2025-02-11T08:45:41.287Z"
   },
   {
    "duration": 16167,
    "start_time": "2025-02-11T08:46:19.184Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:46:35.353Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:46:35.353Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:46:35.354Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:46:35.356Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:46:35.357Z"
   },
   {
    "duration": 849,
    "start_time": "2025-02-11T08:47:10.103Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-11T08:47:10.954Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-11T08:47:11.090Z"
   },
   {
    "duration": 353,
    "start_time": "2025-02-11T08:47:11.937Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-11T08:47:12.382Z"
   },
   {
    "duration": 16605,
    "start_time": "2025-02-11T08:47:13.537Z"
   },
   {
    "duration": 343,
    "start_time": "2025-02-11T08:47:30.144Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-11T08:47:30.489Z"
   },
   {
    "duration": 16278,
    "start_time": "2025-02-11T08:47:30.510Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-11T08:47:46.790Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:47:46.796Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:47:46.797Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:47:46.798Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T08:47:46.799Z"
   },
   {
    "duration": 6617,
    "start_time": "2025-02-11T08:47:55.431Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-11T08:48:02.050Z"
   },
   {
    "duration": 16776,
    "start_time": "2025-02-11T08:48:02.059Z"
   },
   {
    "duration": 16726,
    "start_time": "2025-02-11T08:49:15.439Z"
   },
   {
    "duration": 201,
    "start_time": "2025-02-11T08:49:32.168Z"
   },
   {
    "duration": 810,
    "start_time": "2025-02-11T15:25:15.853Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-11T15:25:16.665Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-11T15:25:17.054Z"
   },
   {
    "duration": 354,
    "start_time": "2025-02-11T15:25:18.085Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-11T15:25:18.592Z"
   },
   {
    "duration": 16483,
    "start_time": "2025-02-11T15:25:19.780Z"
   },
   {
    "duration": 2098,
    "start_time": "2025-02-11T15:25:36.265Z"
   },
   {
    "duration": 32,
    "start_time": "2025-02-11T15:25:38.365Z"
   },
   {
    "duration": 16308,
    "start_time": "2025-02-11T15:25:38.400Z"
   },
   {
    "duration": 6641,
    "start_time": "2025-02-11T15:25:54.710Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-11T15:26:01.353Z"
   },
   {
    "duration": 16977,
    "start_time": "2025-02-11T15:26:01.362Z"
   },
   {
    "duration": 16925,
    "start_time": "2025-02-11T15:26:18.341Z"
   },
   {
    "duration": 73,
    "start_time": "2025-02-11T15:26:35.269Z"
   },
   {
    "duration": 16786,
    "start_time": "2025-02-11T15:27:15.370Z"
   },
   {
    "duration": 300,
    "start_time": "2025-02-11T15:27:54.431Z"
   },
   {
    "duration": 17003,
    "start_time": "2025-02-11T15:28:00.265Z"
   },
   {
    "duration": 65,
    "start_time": "2025-02-11T15:29:25.827Z"
   },
   {
    "duration": 306,
    "start_time": "2025-02-11T15:31:19.305Z"
   },
   {
    "duration": 80,
    "start_time": "2025-02-11T15:31:28.345Z"
   },
   {
    "duration": 93,
    "start_time": "2025-02-11T15:34:05.527Z"
   },
   {
    "duration": 82,
    "start_time": "2025-02-11T15:34:19.337Z"
   },
   {
    "duration": 16470,
    "start_time": "2025-02-11T15:34:37.685Z"
   },
   {
    "duration": 108,
    "start_time": "2025-02-11T15:35:03.833Z"
   },
   {
    "duration": 17026,
    "start_time": "2025-02-11T15:36:10.575Z"
   },
   {
    "duration": 152589,
    "start_time": "2025-02-11T15:40:24.973Z"
   },
   {
    "duration": 135,
    "start_time": "2025-02-11T15:43:39.518Z"
   },
   {
    "duration": 172222,
    "start_time": "2025-02-11T15:44:10.805Z"
   },
   {
    "duration": 75,
    "start_time": "2025-02-11T15:47:03.029Z"
   },
   {
    "duration": 68,
    "start_time": "2025-02-11T16:00:47.230Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-11T16:01:58.716Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-11T16:02:32.050Z"
   },
   {
    "duration": 9305,
    "start_time": "2025-02-11T16:02:36.397Z"
   },
   {
    "duration": 1382,
    "start_time": "2025-02-11T16:02:57.942Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T16:56:42.659Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-11T17:04:53.938Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-11T17:05:11.618Z"
   },
   {
    "duration": 253,
    "start_time": "2025-02-11T17:05:22.589Z"
   },
   {
    "duration": 2213,
    "start_time": "2025-02-11T17:05:34.786Z"
   },
   {
    "duration": 545,
    "start_time": "2025-02-11T17:07:36.208Z"
   },
   {
    "duration": 87,
    "start_time": "2025-02-11T17:08:16.722Z"
   },
   {
    "duration": 155,
    "start_time": "2025-02-11T17:08:50.899Z"
   },
   {
    "duration": 3463,
    "start_time": "2025-02-11T17:09:02.544Z"
   },
   {
    "duration": 255,
    "start_time": "2025-02-11T17:09:23.564Z"
   },
   {
    "duration": 48,
    "start_time": "2025-02-11T17:09:29.598Z"
   },
   {
    "duration": 3446,
    "start_time": "2025-02-11T17:09:35.901Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-11T17:21:02.316Z"
   },
   {
    "duration": 175193,
    "start_time": "2025-02-11T17:23:40.569Z"
   },
   {
    "duration": 3452,
    "start_time": "2025-02-11T17:34:05.582Z"
   },
   {
    "duration": 82,
    "start_time": "2025-02-11T17:34:37.552Z"
   },
   {
    "duration": 811,
    "start_time": "2025-02-11T17:36:19.837Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-11T17:36:20.650Z"
   },
   {
    "duration": 38,
    "start_time": "2025-02-11T17:36:20.663Z"
   },
   {
    "duration": 362,
    "start_time": "2025-02-11T17:36:20.703Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-11T17:36:21.066Z"
   },
   {
    "duration": 3438,
    "start_time": "2025-02-11T17:36:21.094Z"
   },
   {
    "duration": 174534,
    "start_time": "2025-02-11T17:36:24.534Z"
   },
   {
    "duration": 333,
    "start_time": "2025-02-11T17:39:19.070Z"
   },
   {
    "duration": 99,
    "start_time": "2025-02-11T17:39:19.406Z"
   },
   {
    "duration": 16308,
    "start_time": "2025-02-11T17:39:19.507Z"
   },
   {
    "duration": 6678,
    "start_time": "2025-02-11T17:39:35.817Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-11T17:39:42.497Z"
   },
   {
    "duration": 16846,
    "start_time": "2025-02-11T17:39:42.506Z"
   },
   {
    "duration": 16914,
    "start_time": "2025-02-11T17:39:59.353Z"
   },
   {
    "duration": 85,
    "start_time": "2025-02-11T17:40:16.269Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
